<!DOCTYPE HTML>
<html lang="zh-CN">
    <!-- shw2018 洪卫  modify 2019.08.15-->



<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <meta name="keywords" content="pytorch入门, CV DeepLearning MachineLearning 计算机视觉 深度学习">
    <meta name="baidu-site-verification" content="fmlEuI34ir">
    <meta name="google-site-verification" content="KeoTn_OFy4ndJwXNmm2gMeQfPhd7alqE9vQDwI32KCY">
    <meta name="description" content="一.$tensor$的创建:$torch.tensor()$
x_numpy = np.array([0.1, 0.2, 0.3])
x_torch = torch.tensor([0.1, 0.2, 0.3])
print(&#39;x_nump">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>pytorch入门 | dzcixy&#39;s blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    <style type="text/css">
        
            
            code[class*="language-"],
            pre[class*="language-"] {
                white-space: pre !important;
            }

        
    </style>

    <script src="/libs/jquery/jquery-2.2.0.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?46e79e71af0709a5b9106bf20cecc493";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

    
    
        <script>
            (function(){
                var bp = document.createElement('script');
                var curProtocol = window.location.protocol.split(':')[0];
                if (curProtocol === 'https') {
                    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
                }
                else {
                    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
                }
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(bp, s);
            })();
        </script>
    

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

    <body>

        <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">dzcixy's blog</span>
                </a>
            </div>
            


<!-- <a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>首页</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>标签</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>分类</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>归档</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/AV" class="waves-effect waves-light">
            
            <i class="fa fa-music"></i>
            
            <span>视听</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/galleries" class="waves-effect waves-light">
            
            <i class="fa fa-photo"></i>
            
            <span>相册</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>关于我</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/contact" class="waves-effect waves-light">
            
            <i class="fa fa-envelope"></i>
            
            <span>留言板</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>
</ul> -->

<!-- 支持二级菜单特性 洪卫 shw2018 modify 2019.09.17  -->
<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right nav-menu">
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/" class="waves-effect waves-light">
              
                <i class="fa fa-home"></i>
              
              <span>首页</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/tags" class="waves-effect waves-light">
              
                <i class="fa fa-tags"></i>
              
              <span>标签</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/categories" class="waves-effect waves-light">
              
                <i class="fa fa-bookmark"></i>
              
              <span>分类</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/archives" class="waves-effect waves-light">
              
                <i class="fa fa-archive"></i>
              
              <span>归档</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/AV" class="waves-effect waves-light">
              
                <i class="fa fa-music"></i>
              
              <span>视听</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/galleries" class="waves-effect waves-light">
              
                <i class="fa fa-photo"></i>
              
              <span>相册</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/about" class="waves-effect waves-light">
              
                <i class="fa fa-user-circle-o"></i>
              
              <span>关于我</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/contact" class="waves-effect waves-light">
              
                <i class="fa fa-envelope"></i>
              
              <span>留言板</span>
            </a>

            
      </li>
    

    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="搜索"></i>
        </a>
    </li>

</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">dzcixy's blog</div>
        <div class="logo-desc">
            
            计算机视觉
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                首页
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                标签
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                分类
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                归档
            </a>
        </li>
        
        <li>
            <a href="/AV" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-music"></i>
                
                视听
            </a>
        </li>
        
        <li>
            <a href="/galleries" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-photo"></i>
                
                相册
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                关于我
            </a>
        </li>
        
        <li>
            <a href="/contact" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-envelope"></i>
                
                留言板
            </a>
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/dzcixy/dzcixy.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>

   
   
<!-- 支持二级菜单特性 洪卫 shw2018 modify 2019.09.17  -->
<!-- <ul class="menu-list mobile-menu-list">
    
        <li class="m-nav-item">
                
                    <a href="/" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-home"></i>
                        
                        首页
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/tags" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-tags"></i>
                        
                        标签
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/categories" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-bookmark"></i>
                        
                        分类
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/archives" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-archive"></i>
                        
                        归档
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/AV" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-music"></i>
                        
                        视听
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/galleries" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-photo"></i>
                        
                        相册
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/about" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-user-circle-o"></i>
                        
                        关于我
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/contact" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-envelope"></i>
                        
                        留言板
                    </a>
              
            </li>
        

        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/dzcixy/dzcixy.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fa fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul> -->

</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/dzcixy/dzcixy.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

        
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/2.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        pytorch入门
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- shw2018 洪卫  modify 2019.08.15-->
<!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/pytorch/" target="_blank">
                                <span class="chip bg-color">pytorch</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/deep-learning/" class="post-category" target="_blank">
                                deep learning
                            </a>
                        
                    </div>
                    
                </div>
            </div>
            
            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-03-28
                </div>

                <div class="post-author info-break-policy">
                    <i class="fa fa-user-o fa-fw"></i>作者:&nbsp;&nbsp;
                    
                        dzcixy
                    
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>文章字数:&nbsp;&nbsp;
                        2.1k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>阅读时长:&nbsp;&nbsp;
                        11 分
                    </div>
                    
                
                
                
                        <span id="busuanzi_container_site_pv" style='display:none'></span>
                        <i class="fa fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv" ></span>
    
                

            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><strong><em>一.$tensor$的创建:$torch.tensor()$</em></strong></p>
<pre class="line-numbers language-python"><code class="language-python">x_numpy <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x_torch <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x_numpy, x_torch'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_numpy<span class="token punctuation">,</span> x_torch<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre><code> 输出结果为：</code></pre><pre><code>x_numpy, x_torch
[0.1 0.2 0.3] tensor([0.1000, 0.2000, 0.3000])</code></pre><p><strong><em>二.$tensor$和$numpy$矩阵的转换：</em></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'to and from numpy and pytorch'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_numpy<span class="token punctuation">)</span><span class="token punctuation">,</span> x_torch<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>​    输出的结果为：</p>
<pre><code>to and from numpy and pytorch
tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64) [0.1 0.2 0.3]</code></pre><p>需要注意的是： $from\underline{} numpy()$是$torch$的内置函数，输入的是一个$numpy$的对象，输出将其转化为$tensor$类型输出。而$numpy()$是$torch$对象的一个方法，将$tensor$类型的对象转换为$numpy$输出。</p>
<p><strong><em>三.$tensor$和$numpy$矩阵是支持$+，-，*, /$运算的：</em></strong></p>
<pre class="line-numbers language-python"><code class="language-python">y_numpy <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_torch <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x+y"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_numpy <span class="token operator">+</span> y_numpy<span class="token punctuation">,</span> x_torch <span class="token operator">+</span> y_torch<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    输出结果为：</p>
<pre><code>x+y
[3.1 4.2 5.3] tensor([3.1000, 4.2000, 5.3000])</code></pre><p><strong><em>四.许多在$numpy$中的函数，$pytorch$也有：</em></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"norm"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x_numpy<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x_torch<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p><strong><em>五.如果我们只操作一个维度的向量，在$pytorch$中不用$axis$，而是使用$dim$：</em></strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"mean along the 0th dimension"</span><span class="token punctuation">)</span>
x_numpy <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x_torch <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x_numpy<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x_torch<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    输出结果为：</p>
<pre><code>mean along the 0th dimension
[2. 3.] tensor([2., 3.])</code></pre><hr>
<p><strong><em>六.$tensor.view()$可以$reshape tensor$的向量，和$numpy$中的$numpy.reshpe()$效果一样。同样的如果我们不知道一个向量的维度，可以将$-1$填入，他会自动判断向量的维度。</em></strong></p>
<pre class="line-numbers language-python"><code class="language-python">N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> W<span class="token punctuation">,</span> H <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> W<span class="token punctuation">,</span> H<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> C<span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>​    输出结果为：</p>
<pre><code>torch.Size([10000, 3, 28, 28])
torch.Size([10000, 3, 784])
torch.Size([10000, 3, 784])</code></pre><p><strong><em>七.存储计算图：</em></strong></p>
<pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># we set requires_grad=True to let PyTorch know to keep the graph</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> a <span class="token operator">+</span> b
d <span class="token operator">=</span> b <span class="token operator">+</span> <span class="token number">1</span>
e <span class="token operator">=</span> c <span class="token operator">*</span> d
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'c'</span><span class="token punctuation">,</span> c<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'d'</span><span class="token punctuation">,</span> d<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'e'</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<img src="https://cdn.jsdelivr.net/gh/shw2018/cdn@1.0/sakura/img/loader/orange.progress-bar-stripe-loader.svg" data-original="https://colah.github.io/posts/2015-08-Backprop/img/tree-eval.png" alt="img" style="zoom:33%;">

<p>​    输出结果为：</p>
<pre><code>c tensor(3., grad_fn=&lt;AddBackward0&gt;)
d tensor(2., grad_fn=&lt;AddBackward0&gt;)
e tensor(6., grad_fn=&lt;MulBackward0&gt;)</code></pre><p><strong><em>八.可以通过$backward()$函数一次将计算图中的梯度计算出:</em></strong></p>
<pre><code>def f(x):
    return (x-2)**2

def fp(x):
    return 2*(x-2)

x = torch.tensor([1.0], requires_grad=True)

y = f(x)
y.backward()

print('Analytical f\'(x):', fp(x))
print('PyTorch\'s f\'(x):', x.grad)</code></pre><p>可以看到输出的结果是一样的：</p>
<pre><code>Analytical f'(x): tensor([-2.], grad_fn=&lt;MulBackward0&gt;)
PyTorch's f'(x): tensor([-2.])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">g</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">2</span><span class="token operator">*</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">grad_g</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">*</span>w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token operator">*</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

z <span class="token operator">=</span> g<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Analytical grad g(w)'</span><span class="token punctuation">,</span> grad_g<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'PyTorch\'s grad g(w)'</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出：</p>
<pre><code>Analytical grad g(w) tensor([2.0000, 5.2832])
PyTorch's grad g(w) tensor([2.0000, 5.2832])</code></pre><p>有了梯度，我们就可以用来计算梯度下降：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>x<span class="token number">-2</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>

<span class="token keyword">def</span> <span class="token function">fp</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">2</span><span class="token operator">*</span><span class="token punctuation">(</span>x<span class="token number">-2</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
step_size <span class="token operator">=</span> <span class="token number">0.25</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'iter,\tx,\tf(x),\tf\'(x),\tf\'(x) pytorch'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    y <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># compute the gradient</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{},\t{:.3f},\t{:.3f},\t{:.3f},\t{:.3f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">,</span> x<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    x<span class="token punctuation">.</span>data <span class="token operator">=</span> x<span class="token punctuation">.</span>data <span class="token operator">-</span> step_size <span class="token operator">*</span> x<span class="token punctuation">.</span>grad  <span class="token comment" spellcheck="true"># perform a GD update step</span>

    <span class="token comment" spellcheck="true"># We need to zero the grad variable since the backward()</span>
    <span class="token comment" spellcheck="true"># call accumulates the gradients in .grad instead of overwriting.</span>
    <span class="token comment" spellcheck="true"># The detach_() is for efficiency. You do not need to worry too much about it.</span>
    x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>detach_<span class="token punctuation">(</span><span class="token punctuation">)</span>
    x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果：</p>
<pre><code>iter,    x,    f(x),    f'(x),    f'(x) pytorch
0,    5.000,    9.000,    6.000,    6.000
1,    3.500,    2.250,    3.000,    3.000
2,    2.750,    0.562,    1.500,    1.500
3,    2.375,    0.141,    0.750,    0.750
4,    2.188,    0.035,    0.375,    0.375
5,    2.094,    0.009,    0.188,    0.188
6,    2.047,    0.002,    0.094,    0.094
7,    2.023,    0.001,    0.047,    0.047
8,    2.012,    0.000,    0.023,    0.023
9,    2.006,    0.000,    0.012,    0.012
10,    2.003,    0.000,    0.006,    0.006
11,    2.001,    0.000,    0.003,    0.003
12,    2.001,    0.000,    0.001,    0.001
13,    2.000,    0.000,    0.001,    0.001
14,    2.000,    0.000,    0.000,    0.000</code></pre><p><strong><em>九.使用$pytorch$做$Linear Regression$：</em></strong></p>
<p>定义一个简单的线性模型：</p>
<pre class="line-numbers language-python"><code class="language-python">d <span class="token operator">=</span> <span class="token number">2</span>
n <span class="token operator">=</span> <span class="token number">50</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n<span class="token punctuation">,</span>d<span class="token punctuation">)</span>
true_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> X @ true_w <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.1</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'X shape'</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y shape'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w shape'</span><span class="token punctuation">,</span> true_w<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>定义一个无bias的模型。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># define a linear model with no bias</span>
<span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> X @ w

<span class="token comment" spellcheck="true"># the residual sum of squares loss function</span>
<span class="token keyword">def</span> <span class="token function">rss</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>y <span class="token operator">-</span> y_hat<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">/</span> n

<span class="token comment" spellcheck="true"># analytical expression for the gradient</span>
<span class="token keyword">def</span> <span class="token function">grad_rss</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span>X<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> @ <span class="token punctuation">(</span>y <span class="token operator">-</span> X @ w<span class="token punctuation">)</span> <span class="token operator">/</span> n

w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span>

loss <span class="token operator">=</span> rss<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Analytical gradient'</span><span class="token punctuation">,</span> grad_rss<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'PyTorch\'s gradient'</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>进行梯度下降：</p>
<pre class="line-numbers language-python"><code class="language-python">step_size <span class="token operator">=</span> <span class="token number">0.1</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'iter,\tloss,\tw'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> rss<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span>

    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># compute the gradient of the loss</span>

    w<span class="token punctuation">.</span>data <span class="token operator">=</span> w<span class="token punctuation">.</span>data <span class="token operator">-</span> step_size <span class="token operator">*</span> w<span class="token punctuation">.</span>grad <span class="token comment" spellcheck="true"># do a gradient descent step</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{},\t{:.2f},\t{}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># We need to zero the grad variable since the backward()</span>
    <span class="token comment" spellcheck="true"># call accumulates the gradients in .grad instead of overwriting.</span>
    <span class="token comment" spellcheck="true"># The detach_() is for efficiency. You do not need to worry too much about it.</span>
    w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
    w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\ntrue w\t\t'</span><span class="token punctuation">,</span> true_w<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'estimated w\t'</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果：</p>
<pre><code>X shape torch.Size([50, 2])
y shape torch.Size([50, 1])
w shape torch.Size([2, 1])

Analytical gradient [ 2.606523 -3.605597]
PyTorch's gradient [ 2.606523  -3.6055958]
iter,    loss,    w
0,    6.28,    [0.4786954  0.72111917]
1,    2.96,    [0.27993613 0.9474361 ]
2,    2.13,    [0.10609908 1.1325792 ]
3,    1.53,    [-0.04559225  1.2843454 ]
4,    1.11,    [-0.1776925  1.409002 ]
5,    0.80,    [-0.2925274  1.511596 ]
6,    0.58,    [-0.3921964  1.5961986]
7,    0.43,    [-0.47858146  1.6661003 ]
8,    0.31,    [-0.5533598  1.7239654]
9,    0.23,    [-0.6180189  1.7719555]
10,    0.17,    [-0.6738725  1.8118278]
11,    0.13,    [-0.72207654  1.8450135 ]
12,    0.09,    [-0.7636454  1.8726808]
13,    0.07,    [-0.79946655  1.8957849 ]
14,    0.05,    [-0.8303146  1.9151086]
15,    0.04,    [-0.85686433  1.9312946 ]
16,    0.03,    [-0.87970257  1.9448717 ]
17,    0.03,    [-0.8993387  1.9562759]
18,    0.02,    [-0.91621447  1.9658674 ]
19,    0.02,    [-0.9307121  1.9739441]

true w         [-1.  2.]
estimated w     [-0.9307121  1.9739441]</code></pre><p><strong><em>十.接下来使用$torch$的$Module$模块来构建模型：</em></strong></p>
<p>我们只需要给模型输入和输出的向量维度就可以。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn


d_in <span class="token operator">=</span> <span class="token number">3</span>
d_hidden <span class="token operator">=</span> <span class="token number">4</span>
d_out <span class="token operator">=</span> <span class="token number">1</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>
                            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_hidden<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span><span class="token punctuation">,</span>
                            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
                           <span class="token punctuation">)</span>

example_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
transformed <span class="token operator">=</span> model<span class="token punctuation">(</span>example_tensor<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'transformed'</span><span class="token punctuation">,</span> transformed<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以知道我们的模型是输出是$transformed torch.Size([2, 1])$的。</p>
<p>我们可以访问模型的任意参数，使用$model$模块的$parameters()$函数：</p>
<pre class="line-numbers language-python"><code class="language-python">params <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> param <span class="token keyword">in</span> params<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出为：</p>
<pre><code>Parameter containing:
tensor([[-0.1239,  0.3218,  0.0660],
        [ 0.4255, -0.0327,  0.1256],
        [ 0.0171, -0.0812,  0.0283],
        [ 0.2355, -0.5556, -0.5647]], requires_grad=True)
Parameter containing:
tensor([ 0.2152, -0.2082, -0.0993, -0.3068], requires_grad=True)
Parameter containing:
tensor([[ 0.3291, -0.0819,  0.0228,  0.0642]], requires_grad=True)
Parameter containing:
tensor([-0.3666], requires_grad=True)</code></pre><p>接下来需要定义损失函数，可以用$CrossEntropyLoss$或者$MSELoss$：</p>
<pre class="line-numbers language-python"><code class="language-python">mse_loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

input <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

loss <span class="token operator">=</span> mse_loss_fn<span class="token punctuation">(</span>input<span class="token punctuation">,</span> target<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>$pytorch$定义了参数优化器，例如梯度下降等都在$torch.optim$中。</p>
<p>但是它不会为你计算梯度，所以你需要自己调用函数$backward()$，当你调用$backward()$前，你还需要调用$optim.zero\underline{} grad()$,因为$pytorch$的梯度是会相加的而不是覆盖原来的值。</p>
<p>另外类似$torch.optim.SGD()$的后面需要两个参数，一个是模型的参数$model.parameters()$,另一个是学习率$lr$。</p>
<p>一个简单的模型：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># create a simple model</span>
model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># create a simple dataset</span>
X_simple <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_simple <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># create our optimizer</span>
optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
mse_loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>X_simple<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'model params before:'</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
loss <span class="token operator">=</span> mse_loss_fn<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y_simple<span class="token punctuation">)</span>
optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'model params after:'</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong><em>十一.构建卷积神经网络:</em></strong></p>
<p> $pytorch$中有$torch.nn.Conv2d$函数实现卷积。他所需要的参数有四个$(N,C_{in},H_{in},W_{in})$。其中$N$是$batch size$, $C_{in}$是图片的通道数目，$H_{in}$和$W_{in}$分别是图片的高和宽。</p>
<p><strong><em>十二.数据：</em></strong></p>
<p>$torch.utils.data.Dataset$需要覆盖$\underline{}\underline{}len\underline{}\underline{}$和$\underline{}\underline{}getitem\underline{}\underline{}$方法，前者返回数据集的$size$,后者使数据集支持数组的下标寻址方式。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FaceLandmarksDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Face Landmarks dataset."""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> csv_file<span class="token punctuation">,</span> root_dir<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Args:
            csv_file (string): Path to the csv file with annotations.
            root_dir (string): Directory with all the images.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """</span>
        self<span class="token punctuation">.</span>landmarks_frame <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>csv_file<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>root_dir <span class="token operator">=</span> root_dir
        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>landmarks_frame<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>is_tensor<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
            idx <span class="token operator">=</span> idx<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>

        img_name <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>
                                self<span class="token punctuation">.</span>landmarks_frame<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        image <span class="token operator">=</span> io<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>img_name<span class="token punctuation">)</span>
        landmarks <span class="token operator">=</span> self<span class="token punctuation">.</span>landmarks_frame<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        landmarks <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>landmarks<span class="token punctuation">]</span><span class="token punctuation">)</span>
        landmarks <span class="token operator">=</span> landmarks<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        sample <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'image'</span><span class="token punctuation">:</span> image<span class="token punctuation">,</span> <span class="token string">'landmarks'</span><span class="token punctuation">:</span> landmarks<span class="token punctuation">}</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">:</span>
            sample <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>sample<span class="token punctuation">)</span>

        <span class="token keyword">return</span> sample<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            
            <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.88rem;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-large waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fa fa-close"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力!</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.bmp" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.bmp" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone" data-wechat-qrcode-helper="<p>微信里点“发现”->“扫一扫”二维码便可查看分享。</p>"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            
            
            
            <div class="reprint1">
                <p>
                    <span class="reprint1-tip">
                        <i class="fa fa-exclamation-circle"></i>&nbsp;&nbsp;转载请注明:
                    </span>
                    <a href="https://github.com/dzcixy/dzcixy.github.io.git" class="b-link-green">dzcixy's blog</a>
                    <i class="fa fa-angle-right fa-lg fa-fw text-color"></i>
                    <a href="/2020/03/28/pytorch/" class="b-link-green">pytorch入门</a>
                </p>
            </div>

        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'XXXXXXXXXXXXXXXXXXXXXXXXXXXX',
        clientSecret: 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',
        repo: 'dzcixy.github.io',
        owner: 'dzcixy',
        admin: ["dzcixy"],
        id: '2020/03/28/pytorch/',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }
    /* valine 评论框增加背景图片 */
    #vcomments textarea {
        box-sizing: border-box;
        background: url("") 100% 100% no-repeat;
    }

    #vcomments input[type=text],
    #vcomments input[type=email],
    #vcomments input[type=url],
    #vcomments textarea {
        box-sizing: border-box;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #42b983;
        font-weight: 500;
        text-decoration: underline;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    /* 修复评论第一行位置错位 */
    .v .vlist .vcard {
    padding-top: 2.5em !important ;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div id="vcomments" class="card-content"></div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<!-- <link rel="stylesheet" type="text/css" href="/libs//libs/jQuery-emoji/dist/css/jquery.emoji.css">
<script src="/libs//libs/jQuery-emoji/dist/js/jquery.emoji.min.js"></script>
<script src="/libs//libs/jQuery-emoji/dist/js/emoji.list.js"></script> -->
<script>
    new Valine({
        el: '#vcomments',
        appId: 'XXXXXXXXXXXXXXXXXXXXXXXX',
        appKey: 'XXXXXXXXXXXXXXXXXXXXXX',
        notify: 'true' === 'true',
        verify: 'true' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'just go go',

    });

//     function parse_emoji() {
//     jQuery(".vcontent").emojiParse({
//       basePath: '/libs/jQuery-emoji/images/emoji',
//       icons: emojiLists   // 注：详见 js/emoji.list.js
//     });
//   }
  
//   setTimeout(function() {
//     // jQuery emoji 解析
//     parse_emoji();
//     // jquery emoji 初始化
//     jQuery(".veditor").emoji({
//       showTab: true,
//       animation: 'slide',
//       basePath: '/libs/jQuery-emoji/images/emoji',
//       icons: emojiLists  // 注：详见 js/emoji.list.js
//     });
//     jQuery(".vmore").on("click", function() {
//       setTimeout(function() {
//         parse_emoji();
//       }, 500);
//     });
//   }, 800)

</script>
    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/03/29/tips-for-dnn/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/5.jpg" class="responsive-img" alt="Tips for Training DNN">
                        
                        <span class="card-title">Tips for Training DNN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            构建深度学习的三个步骤：①定义一系列函数$(define \ a \ set \ of \ function)$②函数的拟合程度$(goodness \ of \ function)$③选出最优的模型$(pick \ the \ best 
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2020-03-29
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/deep-learning/" class="post-category" target="_blank">
                                    deep learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Training-DNN/" target="_blank">
                        <span class="chip bg-color">Training DNN</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/03/28/python-wen-jian-shu-ru-shu-chu/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/4.jpg" class="responsive-img" alt="python文件输入输出">
                        
                        <span class="card-title">python文件输入输出</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            python读取文件使用open函数，返回一个文本对象，我们一般只会用到open函数的前面两个参数，第一个参数是要读取文件的名称，第二个参数是读取文件的模式。  



打开模式
执行操作



‘r’
以只读方式打开文件（默认）


‘w
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2020-03-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/deep-learning/" class="post-category" target="_blank">
                                    deep learning
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/python文件处理/" target="_blank">
                        <span class="chip bg-color">python文件处理</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: dzcixy's blog<br />'
            + '作者: dzcixy<br />'
            + '链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4, h5'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4, h5').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

        <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            Copyright&copy; dzcixy. 

            <br>
            <span id="sitetime"></span><span class="my-face">ღゝ◡╹)ノ♡</span>
            <br>

            

            
                    
                        <span id="busuanzi_container_site_pv" style='display:none'></span>
                        总访问量: <span id="busuanzi_value_site_pv" class="white-color"></span>
                    
        
                    
                        <span id="busuanzi_container_site_uv" style='display:none'></span>
                        人次&nbsp; | &nbsp;访客人数: <span id="busuanzi_value_site_uv" class="white-color"></span> 人
                    
    
            

            
                &nbsp; | &nbsp;字数统计:&nbsp;
                <span class="white-color">8.7k</span> 字
            

            
            <br>

        </div>

        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/dzcixy" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>


 
    <a href="https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=961554798@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fa fa-envelope-open"></i>
    </a>






    <a href="http://wpa.qq.com/msgrd?v=3&uin=961554798&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的QQ空间" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>





    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fa fa-rss"></i>
    </a>
</div>

    </div>
</footer>

<div class="progress-bar"></div>

<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();

        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */

        var t1 = Date.UTC(2019, 08, 10, 00, 00, 00); //北京时间2019-8-1 00:00:00
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes *
            minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已勉强运行 " + diffYears + " 年 " + diffDays + " 天 " + diffHours +
            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒" ;
    } /*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
</script>






        <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
        <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


        <script src="/libs/materialize/materialize.min.js"></script>
        <script src="/libs/masonry/masonry.pkgd.min.js"></script>
        <script src="/libs/aos/aos.js"></script>
        <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
        <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
        <script src="/js/matery.js"></script>

        <!-- Global site tag (gtag.js) - Google Analytics -->



        
            <script src="/libs/others/clicklove.js"></script>
        

        
            <script async src="/libs/others/busuanzi.pure.mini.js"></script>
        

        <!-- 洪卫 shw2018 add 2019.08.28 -->
        <script type="text/javascript">
            var OriginTitile = document.title,
                st;
            document.addEventListener("visibilitychange", function () {
                document.hidden ? (document.title = "看不见我🙈~看不见我🙈~", clearTimeout(st)) : (document.title =
                    "(๑•̀ㅂ•́) ✧被发现了～", st = setTimeout(function () {
                        document.title = OriginTitile
                    }, 3e3))
            })
        </script>

        <!-- 鼠标点击烟花爆炸效果  洪卫 shw2018 add 2019.09.09 -->
        
            <canvas class="fireworks" style="position: fixed; left: 0; top: 0; z-index: 1; pointer-events: none;"></canvas>
            <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
            <script type="text/javascript" src="/js/fireworks.js"></script>
        

        <!-- 背景雪花飘落特效洪卫 shw2018 add 2019.09.10 -->
        
            <script type="text/javascript">
            //只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>');
            }
            </script>
        

        <!-- 鼠标点击文字特效 洪卫 shw2018 add 2019.09.10-->
        
            <script src="/js/wenzi.js" type="text/javascript"></script>
        

        <!-- 背景雪花飘落特效 洪卫 shw2018 add 2019.09.10 -->
        
            <script type="text/javascript">
                var windowWidth = $(window).width();
                if (windowWidth > 768) {
                    document.write('<script type="text/javascript" src="/js/xuehuapiaoluo.js"><\/script>');
                }
            </script>
        

        <!-- 在线聊天工具  洪卫 shw2018 add 2019.09.11 -->
        
            <script src="//code.tidio.co/xxxxxxxxxxxxxxxxxxxxxxxxxxx.js"></script>
            <!--  在线聊天位置自定义  洪卫 shw2018 add 2019.09.13  -->
            <script> 
                $(document).ready(function () {

                    setInterval(change_Tidio, 50);  
                    function change_Tidio() { 

                        var tidio=$("#tidio-chat iframe");
                        if(tidio.css("display")=="block"&& $(window).width()>977 ){
                            document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"80px":"20px";   
                            document.getElementById("tidio-chat-iframe").style.right="-15px";   
                            document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                            document.getElementById("tidio-chat-iframe").style.zIndex="997";
                        } 
                        else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                            document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                            document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                            document.getElementById("tidio-chat-iframe").style.zIndex="997";
                        }
                        else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                            document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                            document.getElementById("tidio-chat-iframe").style.zIndex="997";
                        }

                        if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                            document.getElementById("tidio-chat-iframe").style.zIndex="998";
                        }
                    } 
                }); 
            </script>
        

        <!-- 背景 canvas-nest  洪卫 shw 2018  add 2019.09.15-->
        
            <script type="text/javascript">
            var windowWidth = $(window).width();
            if (windowWidth > 992) {
                document.write('<script type="text/javascript" color="0,0,255" pointColor="0,0,255" opacity= "0.8" zIndex="--1" count="150"src="/libs/background/canvas-nest.js"><\/script>');
            }
            </script>
        

        <!-- 背景静止彩带  洪卫 shw 2018  add 2019.09.15-->
        

        <!-- 背景动态彩带 洪卫 shw 2018  add 2019.09.15-->
        
            <script type="text/javascript">
            var windowWidth = $(window).width();
            if (windowWidth > 992) {
                document.write('<script type="text/javascript" src="/libs/background/ribbon-dynamic.js"><\/script>');
            }
            </script>
        

    <script>!function(e){var r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function t(){for(var c=0;c<r.length;c++)t=r[c],void 0,0<=(n=t.getBoundingClientRect()).top&&0<=n.left&&n.top<=(e.innerHeight||document.documentElement.clientHeight)&&function(){var t,n,e,i,o=r[c];t=o,n=function(){r=r.filter(function(t){return o!==t})},e=new Image,i=t.getAttribute("data-original"),e.onload=function(){t.src=i,n&&n()},e.src=i}();var t,n}t(),e.addEventListener("scroll",function(){!function(t,n){clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(n)},500)}(t,e)})}(this);</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":200},"mobile":{"show":false},"react":{"opacity":0.7}});</script></body>
</html>