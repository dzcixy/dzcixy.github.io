<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GoogLe Net</title>
      <link href="/2020/06/29/google/"/>
      <url>/2020/06/29/google/</url>
      
        <content type="html"><![CDATA[<script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>VGG Net</title>
      <link href="/2020/06/28/vgg/"/>
      <url>/2020/06/28/vgg/</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>VGG是Oxford的Visual Geometry Group的组提出的，取三个单词的首字母，也是该网络名字的由来。该网络是在ILSVRC 2014上的第二名，主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。VGG有两种结构，分别是VGG16和VGG19，两者并没有本质上的区别，只是网络深度不一样。VGG的泛化能力非常好，在不同的图片数据集上都有良好的表现。到目前为止，VGG依然经常被用来提取特征图像。</p><h3 id="VGG的网络架构"><a href="#VGG的网络架构" class="headerlink" title="VGG的网络架构"></a>VGG的网络架构</h3><img src="https://cdn.jsdelivr.net/gh/shw2018/cdn@1.0/sakura/img/loader/orange.progress-bar-stripe-loader.svg" data-original="/2020/06/28/vgg/1.png"><img src="https://cdn.jsdelivr.net/gh/shw2018/cdn@1.0/sakura/img/loader/orange.progress-bar-stripe-loader.svg" data-original="/2020/06/28/vgg/2.png"><p>B与C的差别就是C比B多了一些1X1的卷积核，1X1的卷积核主要用来降维，这里主要是用来做非线性变换。VGG的架构很简单，就是通过不断的堆叠卷积层和池化层增加网络的深度，之后用全连接层将其铺平输出。</p><h3 id="VGG原理"><a href="#VGG原理" class="headerlink" title="VGG原理"></a>VGG原理</h3><h4 id="小卷积核代替大卷积"><a href="#小卷积核代替大卷积" class="headerlink" title="小卷积核代替大卷积"></a>小卷积核代替大卷积</h4><p>对于网络深度，虽然AlexNet有使用了11x11和5x5的大卷积，但大多数还是3x3卷积，对于stride=4的11x11的大卷积核，一开始原图的尺寸很大因而冗余，最为原始的纹理细节的特征变化用大卷积核尽早捕捉到，后面的更深的层数害怕会丢失掉较大局部范围内的特征相关性，后面转而使用更多3x3的小卷积核（和一个5x5卷积）去捕捉细节变化。</p><p>而VGGNet则清一色使用3x3卷积。因为卷积不仅涉及到计算量，还影响到感受野。前者关系到是否方便部署到移动端、是否能满足实时处理、是否易于训练等，后者关系到参数更新、特征图的大小、特征是否提取的足够多、模型的复杂度和参数量等等。</p><p>VGG通过3x3的卷积来代替5x5，7x7， 11x11的卷积，下图展示了如何通过两个3x3的卷积代替一个5x5的卷积的感受野：</p><img src="https://cdn.jsdelivr.net/gh/shw2018/cdn@1.0/sakura/img/loader/orange.progress-bar-stripe-loader.svg" data-original="/2020/06/28/vgg/3.png"><h3 id="VGG的优缺点"><a href="#VGG的优缺点" class="headerlink" title="VGG的优缺点"></a>VGG的优缺点</h3><h4 id="VGG的优点"><a href="#VGG的优点" class="headerlink" title="VGG的优点"></a>VGG的优点</h4><blockquote><ul><li><p>架构简单，整个网络使用同样大小(3x3)的卷积核尺寸和同样大小(2x2)的池化层尺寸。</p></li><li><p>证明了使用小的卷积核代替大的卷积核效果更好。</p></li><li><p>验证了通过不断堆叠网络的深度可以提高网络的性能</p></li></ul></blockquote><h4 id="VGG的缺点"><a href="#VGG的缺点" class="headerlink" title="VGG的缺点"></a>VGG的缺点</h4><blockquote><ul><li>VGG网络的参数庞大，意味着需要消耗更多的计算资源，其中绝大部分的参数都来自全连接层。</li></ul></blockquote><h4 id="VGG网络的搭建"><a href="#VGG网络的搭建" class="headerlink" title="VGG网络的搭建"></a>VGG网络的搭建</h4><p>使用pytorch搭建的VGG网络代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token keyword">class</span> <span class="token class-name">VGG</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">,</span> class_num<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> init_weights<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>VGG<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>features <span class="token operator">=</span> features        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> class_num<span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">if</span> init_weights<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>_initialize_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># N x 3 x 224 x 224</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># N x 512 x 7 x 7</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># N x 512*7*7</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x    <span class="token keyword">def</span> <span class="token function">_initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>                <span class="token keyword">if</span> m<span class="token punctuation">.</span>bias <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>                    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">elif</span> isinstance<span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># nn.init.normal_(m.weight, 0, 0.01)</span>                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">make_features</span><span class="token punctuation">(</span>cfg<span class="token punctuation">:</span> list<span class="token punctuation">)</span><span class="token punctuation">:</span>    layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    in_channels <span class="token operator">=</span> <span class="token number">3</span>    <span class="token keyword">for</span> v <span class="token keyword">in</span> cfg<span class="token punctuation">:</span>        <span class="token keyword">if</span> v <span class="token operator">==</span> <span class="token string">"M"</span><span class="token punctuation">:</span>            layers <span class="token operator">+=</span> <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            conv2d <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> v<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            layers <span class="token operator">+=</span> <span class="token punctuation">[</span>conv2d<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            in_channels <span class="token operator">=</span> v    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>cfgs <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'vgg11'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'vgg13'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'vgg16'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token string">'vgg19'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">}</span><span class="token keyword">def</span> <span class="token function">vgg</span><span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"vgg16"</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        cfg <span class="token operator">=</span> cfgs<span class="token punctuation">[</span>model_name<span class="token punctuation">]</span>    <span class="token keyword">except</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Warning: model number {} not in cfgs dict!"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span><span class="token punctuation">)</span>        exit<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    model <span class="token operator">=</span> VGG<span class="token punctuation">(</span>make_features<span class="token punctuation">(</span>cfg<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VGG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用pytorch实现手写数字识别</title>
      <link href="/2020/05/29/mnist/"/>
      <url>/2020/05/29/mnist/</url>
      
        <content type="html"><![CDATA[<p>使用mnist数据集实现手写数字识别是入门必做吧。这里使用pyTorch框架进行简单神经网络的搭建。</p><p>首先导入需要的包。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data<span class="token keyword">import</span> torchvision<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>接下来需要下载mnist数据集。我们创建train_data。使用torchvision.datasets.MNIST进行数据集的下载。</p><pre class="line-numbers language-python"><code class="language-python">train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'./mnist/'</span><span class="token punctuation">,</span>   <span class="token comment" spellcheck="true">#下载到该目录下</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                     <span class="token comment" spellcheck="true">#为训练数据</span>    transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true">#将其装换为tensor的形式</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">#第一次设置为true表示下载，下载完成后，将其置成false</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>之后将其导入data_loader中，这个数据加载类会自动帮我们进行数据集的切片。</p><pre class="line-numbers language-python"><code class="language-python">train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'./mnist'</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">'./mnist'</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>test_num <span class="token operator">=</span> len<span class="token punctuation">(</span>test_data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>之后开始定义我们的模型，由于minist数据集是灰度图像，并且图片的size都是（28， 28， 1），所以输入图片的时候不需要进行额外的修改。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token comment" spellcheck="true">#(1, 28, 28)</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#(16, 28, 28)</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#(16, 28, 28)</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#(16, 14, 14)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#(32, 14, 14)</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#(32, 14, 14)</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#(32, 7, 7)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>特别注意在最后传入全连接层时，最好自己将x的size改变以确保不会因为自适应而造成错误。因为在传入全连接层时会默认压缩成二维，例如[1, 2, 3, 4]会被压缩成[1<em>2, 3</em>4]。</p><p>之后开始训练。</p><pre class="line-numbers language-python"><code class="language-python">net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">)</span>save_path <span class="token operator">=</span> <span class="token string">'./mnist.pth'</span>best_acc <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">for</span> step<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> start<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        images<span class="token punctuation">,</span> labels <span class="token operator">=</span> data        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        logits <span class="token operator">=</span> net<span class="token punctuation">(</span>images<span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        rate <span class="token operator">=</span> <span class="token punctuation">(</span>step<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>len<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>        a <span class="token operator">=</span> <span class="token string">"*"</span> <span class="token operator">*</span> int<span class="token punctuation">(</span>rate <span class="token operator">*</span> <span class="token number">50</span><span class="token punctuation">)</span>        b <span class="token operator">=</span> <span class="token string">"."</span> <span class="token operator">*</span> int<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> rate<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">50</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\rtrain loss: {:^3.0f}%[{}->{}]{:.4f}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>int<span class="token punctuation">(</span>rate<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    net<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    acc <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> data_test <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>            test_images<span class="token punctuation">,</span> test_labels <span class="token operator">=</span> data_test            outputs <span class="token operator">=</span> net<span class="token punctuation">(</span>test_images<span class="token punctuation">)</span>            predict_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#torch.max返回两个数值，一个是最大值，一个是最大值的下标</span>            acc <span class="token operator">+=</span> <span class="token punctuation">(</span>predict_y <span class="token operator">==</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        test_accurate <span class="token operator">=</span> acc <span class="token operator">/</span> test_num        <span class="token keyword">if</span> test_accurate <span class="token operator">></span> best_acc<span class="token punctuation">:</span>            best_acc <span class="token operator">=</span> test_accurate            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[epoch %d] train_loss: %.3f  test_accuracy: %.3f'</span> <span class="token operator">%</span>              <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> running_loss <span class="token operator">/</span> step<span class="token punctuation">,</span> test_accurate<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Finished Training'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在完成训练后，训练的权重会保存在所设置路径下的文件中，进行预测的时候，建立模型，载入权重，照一张数字的图片，对其进行裁剪，灰度等操作之后加载入模型进行预测。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">import</span>  matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token keyword">import</span> torch<span class="token keyword">from</span> model <span class="token keyword">import</span> Netimg <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">"./YLY2@}8UMGLW37S$)NCVZ23.png"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># [N, C, H, W]</span>train_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>        transforms<span class="token punctuation">.</span>Grayscale<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>img <span class="token operator">=</span> train_transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># expand batch dimension</span>img <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>img<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># create model</span>model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># load model weights</span>model_weight_path <span class="token operator">=</span> <span class="token string">"./mnist.pth"</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_weight_path<span class="token punctuation">)</span><span class="token punctuation">)</span>index_to_class <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token string">'1'</span><span class="token punctuation">,</span> <span class="token string">'2'</span><span class="token punctuation">,</span> <span class="token string">'3'</span><span class="token punctuation">,</span> <span class="token string">'4'</span><span class="token punctuation">,</span> <span class="token string">'5'</span><span class="token punctuation">,</span> <span class="token string">'6'</span><span class="token punctuation">,</span> <span class="token string">'7'</span><span class="token punctuation">,</span> <span class="token string">'8'</span><span class="token punctuation">,</span> <span class="token string">'9'</span><span class="token punctuation">]</span>model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># predict class</span>    y <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#print(y.size())</span>    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>y<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#print(output)</span>    predict <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#print(predict)</span>    predict_cla <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>predict<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#print(predict_cla)</span><span class="token keyword">print</span><span class="token punctuation">(</span>index_to_class<span class="token punctuation">[</span>predict_cla<span class="token punctuation">]</span><span class="token punctuation">,</span> predict<span class="token punctuation">[</span>predict_cla<span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>需要注意的是，载入模型的图片必须多一个维度batch，所以我们用img = torch.unsqueeze(img, dim=0）在图片的开头增加一个batch维度。</p><p>之后载入图片，得到输出，将输出的batch维度压缩掉，使用softmax函数得到概率分布，再用argmax函数得到最大值的下标，打印最大值所对应的类别及其概率。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mnist </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN食物分类</title>
      <link href="/2020/03/31/cnn/"/>
      <url>/2020/03/31/cnn/</url>
      
        <content type="html"><![CDATA[<p>首先导入需要使用的包：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> cv2<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> Dataset<span class="token keyword">import</span> time<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>观察数据集，在training,validation,testing文件夹中，都是有许多食物图片，图片命名的名称是”x_y”，其中x是食物的类别，y是食物在该类别中的序号。</p><p>由于每一张的图片的size是不一样的，我们要将其以（128,128,3）的大小读入并存储在Numpy array中。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">readfile</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#label是一个boolean的变量，表示是否有标签</span>    image_dir <span class="token operator">=</span> sorted<span class="token punctuation">(</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#初始化存放图片和标签的矩阵</span>    x <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>len<span class="token punctuation">(</span>image_dir<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> unit8<span class="token punctuation">)</span>    y <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>len<span class="token punctuation">(</span>image_dir<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> unit8<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#将图片读入</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> file <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>image_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> file<span class="token punctuation">)</span><span class="token punctuation">)</span>        x<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span> <span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>img<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> label<span class="token punctuation">:</span>            y<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> int<span class="token punctuation">(</span>file<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> label<span class="token punctuation">:</span>        <span class="token keyword">return</span> x<span class="token punctuation">,</span> y    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样，通过readfile函数，我们可以将数据集(training)，验证集(validation)，测试集(testing)取出来。</p><pre class="line-numbers language-python"><code class="language-python">workspace_dir <span class="token operator">=</span> <span class="token string">"./food-11"</span>train_x<span class="token punctuation">,</span> train_y <span class="token operator">=</span> readfile<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>workspace_dir<span class="token punctuation">,</span> <span class="token string">"training"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>val_x<span class="token punctuation">,</span> val_y <span class="token operator">=</span> readfile<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>workspace_dir<span class="token punctuation">,</span> <span class="token string">"validation"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>test_x<span class="token punctuation">.</span> test_y <span class="token operator">=</span> readfile<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>workspace_dir<span class="token punctuation">,</span> <span class="token string">"testing"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在 Pytorch 中，我們可以利用 torch.utils.data 的 Dataset 及 DataLoader 來”包裝” data，使后序的 training 及 testing 更方便。</p><p>Dataset 需要 overload 两个函数：__len__ 及 __getitem__</p><p>__len__ 必须要回传dataset 的大小，而 __getitem__ 则定义了程序利用 [ ] 取值时，dataset 应该怎样传回所对应的数据。</p><p>实际上我们并不会直接用到这两个函数，但是使用 DataLoader 在 enumerate Dataset 时会使用到，沒有覆盖的话会在程序运行阶段出现 error。</p><p>中文文档：<br><a href="https://pytorch-cn.readthedocs.io/zh/latestpackage_references/data/" target="_blank" rel="noopener">https://pytorch-cn.readthedocs.io/zh/latestpackage_references/data/</a></p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#training 时做 data augmentation</span>train_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">#随机将图片水平翻转，05概率</span>    transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">#随机旋转图片</span>    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">#將图片转成Tensor，并把数值normalize到[0,1](data normalization)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#testing时不需要data augmentation</span>test_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">ImgDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token operator">=</span>None<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        <span class="token comment" spellcheck="true"># label is required to be a LongTensor</span>        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y        <span class="token keyword">if</span> y <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>x<span class="token punctuation">[</span>index<span class="token punctuation">]</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            X <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>y <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            Y <span class="token operator">=</span> self<span class="token punctuation">.</span>y<span class="token punctuation">[</span>index<span class="token punctuation">]</span>            <span class="token keyword">return</span> X<span class="token punctuation">,</span> Y        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>接下来将设置batch_size,然后将数据集载入DataLoader。</p><pre class="line-numbers language-python"><code class="language-python">batch_size <span class="token operator">=</span> <span class="token number">128</span>train_set <span class="token operator">=</span> ImgDataset<span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> train_transform<span class="token punctuation">)</span>val_set <span class="token operator">=</span> ImgDataset<span class="token punctuation">(</span>val_x<span class="token punctuation">,</span> val_y<span class="token punctuation">,</span> test_transform<span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>val_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在开始创建模型：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Classifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Classifier<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span>        <span class="token comment" spellcheck="true">#torch.nn.MaxPool2d(kernel_size, stride, padding)</span>        <span class="token comment" spellcheck="true">#input 維度 [3, 128, 128]</span>        self<span class="token punctuation">.</span>cnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># [64, 128, 128]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># [64, 64, 64]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># [128, 64, 64]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># [128, 32, 32]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># [256, 32, 32]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># [256, 16, 16]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># [512, 16, 16]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token comment" spellcheck="true"># [512, 8, 8]</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># [512, 8, 8]</span>            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>       <span class="token comment" spellcheck="true"># [512, 4, 4]</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token operator">*</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        out <span class="token operator">=</span> self<span class="token punctuation">.</span>cnn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        out <span class="token operator">=</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span>out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>接下来使用training set训练，在用validation set寻找好的参数。</p><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 因為是 classification task，所以 loss 使用 CrossEntropyLoss</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># optimizer 使用 Adam</span>num_epoch <span class="token operator">=</span> <span class="token number">30</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    epoch_start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    train_acc <span class="token operator">=</span> <span class="token number">0.0</span>    train_loss <span class="token operator">=</span> <span class="token number">0.0</span>    val_acc <span class="token operator">=</span> <span class="token number">0.0</span>    val_loss <span class="token operator">=</span> <span class="token number">0.0</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 确保 model 是在 train model (开启 Dropout 等...)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 用 optimizer 將 model 参数的 gradient 清零</span>        train_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 利用 model 得到预测的概率分布 实际是上call model 的 forward 函数</span>        batch_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>train_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 计算 loss （注意 prediction 跟 label 必须同时在 CPU 或者 GPU 上）</span>        batch_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 利用 back propagation 算出每个参数的 gradient</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 以 optimizer 用 gradient 更新参数值</span>        train_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>train_pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        train_loss <span class="token operator">+=</span> batch_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>val_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            val_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            batch_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>val_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            val_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>val_pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            val_loss <span class="token operator">+=</span> batch_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#將結果 print 出來</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f'</span> <span class="token operator">%</span> \            <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> num_epoch<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>epoch_start_time<span class="token punctuation">,</span> \             train_acc<span class="token operator">/</span>train_set<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> train_loss<span class="token operator">/</span>train_set<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> val_acc<span class="token operator">/</span>val_set<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> val_loss<span class="token operator">/</span>val_set<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>找到更好的参数以后，将training set和validation set合并训练，增加数据集的数量。</p><pre class="line-numbers language-python"><code class="language-python">train_val_x <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_x<span class="token punctuation">,</span> val_x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>train_val_y <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_y<span class="token punctuation">,</span> val_y<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>train_val_set <span class="token operator">=</span> ImgDataset<span class="token punctuation">(</span>train_val_x<span class="token punctuation">,</span> train_val_y<span class="token punctuation">,</span> train_transform<span class="token punctuation">)</span>train_val_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_val_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>进行训练。</p><pre class="line-numbers language-python"><code class="language-python">model_best <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 因為是 classification task，所以 loss 使用 CrossEntropyLoss</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model_best<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># optimizer 使用 Adam</span>num_epoch <span class="token operator">=</span> <span class="token number">30</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    epoch_start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    train_acc <span class="token operator">=</span> <span class="token number">0.0</span>    train_loss <span class="token operator">=</span> <span class="token number">0.0</span>    model_best<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_val_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        train_pred <span class="token operator">=</span> model_best<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        batch_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>train_pred<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        batch_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        train_acc <span class="token operator">+=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>train_pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        train_loss <span class="token operator">+=</span> batch_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#將結果 print 出來</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f'</span> <span class="token operator">%</span> \      <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> num_epoch<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>epoch_start_time<span class="token punctuation">,</span> \      train_acc<span class="token operator">/</span>train_val_set<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> train_loss<span class="token operator">/</span>train_val_set<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将最后训练好的模型来预测结果。</p><pre class="line-numbers language-python"><code class="language-python">test_set <span class="token operator">=</span> ImgDataset<span class="token punctuation">(</span>test_x<span class="token punctuation">,</span> transform<span class="token operator">=</span>test_transform<span class="token punctuation">)</span>test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>model_best<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>prediction <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        test_pred <span class="token operator">=</span> model_best<span class="token punctuation">(</span>data<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        test_label <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>test_pred<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> y <span class="token keyword">in</span> test_label<span class="token punctuation">:</span>            prediction<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将结果写入csv文档中</span><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"predict.csv"</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'Id,Category\n'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> y <span class="token keyword">in</span>  enumerate<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span><span class="token punctuation">:</span>        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'{},{}\n'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python函数</title>
      <link href="/2020/03/30/python-han-shu/"/>
      <url>/2020/03/30/python-han-shu/</url>
      
        <content type="html"><![CDATA[<p><strong>本文用来记录python在deep learning中读取数据时所需要用到的一些函数。</strong></p><p>一.os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。</p><p>它不包括 . 和 .. 即使它在文件夹中。</p><p>只支持在 Unix, Windows 下使用。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token punctuation">,</span> sys<span class="token comment" spellcheck="true"># 打开文件</span>path <span class="token operator">=</span> <span class="token string">"/var/www/html/"</span>dirs <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span> path <span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 输出所有文件和文件夹</span><span class="token keyword">for</span> file <span class="token keyword">in</span> dirs<span class="token punctuation">:</span>   <span class="token keyword">print</span> file<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出为：</p><pre><code>test.htmstampfaq.htm_vti_txtrobots.txtitemlistingresumelistingwriting_effective_resume.htmadvertisebusiness.htmpapersresume</code></pre><p>二.python路径拼接os.path.join()函数的用法<br>os.path.join()函数：连接两个或更多的路径名组件</p><p>1.如果各组件名首字母不包含’/‘，则函数会自动加上<br>2.如果有一个组件是一个绝对路径，则在它之前的所有组件均会被舍弃<br>3.如果最后一个组件为空，则生成的路径以一个’/’分隔符结尾</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> osPath1 <span class="token operator">=</span> <span class="token string">'a'</span>Path2 <span class="token operator">=</span> <span class="token string">'b'</span>Path3 <span class="token operator">=</span> <span class="token string">'c'</span>Path10 <span class="token operator">=</span> Path1 <span class="token operator">+</span> Path2 <span class="token operator">+</span> Path3Path20 <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>Path1<span class="token punctuation">,</span>Path2<span class="token punctuation">,</span>Path3<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'Path10 = '</span><span class="token punctuation">,</span>Path10<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'Path20 = '</span><span class="token punctuation">,</span>Path20<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Path10 = abcPath20 = a\b\c</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> osPath1 <span class="token operator">=</span> <span class="token string">'a'</span>Path2 <span class="token operator">=</span> <span class="token string">'b'</span>Path3 <span class="token operator">=</span> <span class="token string">'/c'</span>Path10 <span class="token operator">=</span> Path1 <span class="token operator">+</span> Path2 <span class="token operator">+</span> Path3Path20 <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>Path1<span class="token punctuation">,</span>Path2<span class="token punctuation">,</span>Path3<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'Path10 = '</span><span class="token punctuation">,</span>Path10<span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">'Path20 = '</span><span class="token punctuation">,</span>Path20 <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Path10 = ab/cPath20 = /c</code></pre><p>三.python的split()函数</p><p>python split() 通过指定分隔符对字符串进行切片，如果参数 num 有指定值，则分隔 num+1 个子字符串</p><pre class="line-numbers language-python"><code class="language-python">str<span class="token punctuation">.</span>split<span class="token punctuation">(</span>str<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span> num<span class="token operator">=</span>string<span class="token punctuation">.</span>count<span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>str -- 分隔符，默认为所有的空字符，包括空格、换行(\n)、制表符(\t)等。  num -- 分割次数。默认为 -1, 即分隔所有。</code></pre><pre class="line-numbers language-python"><code class="language-python">str <span class="token operator">=</span> <span class="token string">"1_2"</span><span class="token keyword">print</span><span class="token punctuation">(</span>str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'_'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>12</code></pre><p>四.numpy中的argmax函数：<br>arg函数是用来取出列表中最大的数的索引。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">10</span><span class="token operator">>></span><span class="token operator">></span> aarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token number">5</span><span class="token operator">>></span><span class="token operator">></span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中axis=0代表寻找每一列中最大数的索引，axis=1代表行。</p><p>五.pytorch中的item()函数<br>item函数是将张量tensor转变为数值的函数。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>值得注意的是item函数要在张量只有一个值的时候才可以使用。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> function of python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The different between model.eval() and with torch.no_grad()</title>
      <link href="/2020/03/30/pytorch-zhu-yi-shi-xiang/"/>
      <url>/2020/03/30/pytorch-zhu-yi-shi-xiang/</url>
      
        <content type="html"><![CDATA[<p>两者区别<br>在PyTorch中进行validation时，会使用model.eval()切换到测试模式，在该模式下，<br>主要用于通知dropout层和batchnorm层在train和val模式间切换<br>在train模式下，dropout网络层会按照设定的参数p设置保留激活单元的概率（保留概率=p); batchnorm层会继续计算数据的mean和var等参数并更新。<br>在val模式下，dropout层会让所有的激活单元都通过，而batchnorm层会停止计算和更新mean和var，直接使用在训练阶段已经学出的mean和var值。<br>该模式不会影响各层的gradient计算行为，即gradient计算和存储与training模式一样，只是不进行反传（backprobagation）  </p><p><strong>简单来讲，就是在训练时，model.eval()，让model变成测试模式，对dropout和batch normalization的操作在训练和测试的时候是不一样的，在训练时开启dropout，而测试时是需要固定的。eval（）时，pytorch会自动把BN和DropOut固定住，不会取平均，而是用训练好的值。不然的话，一旦test的batch_size过小，很容易就会被BN层导致生成图片颜色失真极大。</strong></p><p>而with torch.zero_grad()则主要是用于停止autograd模块的工作，以起到加速和节省显存的作用，具体行为就是停止gradient计算，从而节省了GPU算力和显存，但是并不会影响dropout和batchnorm层的行为。</p><p>使用场景<br>如果不在意显存大小和计算时间的话，仅仅使用model.eval()已足够得到正确的validation的结果；而with torch.zero_grad()则是更进一步加速和节省gpu空间（因为不用计算和存储gradient），从而可以更快计算，也可以跑更大的batch来测试。</p><p>参考：<a href="http://sdsy888.me/%E6%A1%86%E6%9E%B6-Framework/%E9%9A%8F%E7%AC%94-Writing/2020/pytorch%E4%B8%ADmodel-eval-%E5%92%8C%E2%80%9Cwith-torch-no-grad-%E5%8C%BA%E5%88%AB/" target="_blank" rel="noopener">http://sdsy888.me/%E6%A1%86%E6%9E%B6-Framework/%E9%9A%8F%E7%AC%94-Writing/2020/pytorch%E4%B8%ADmodel-eval-%E5%92%8C%E2%80%9Cwith-torch-no-grad-%E5%8C%BA%E5%88%AB/</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> function of model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tips for Training DNN</title>
      <link href="/2020/03/29/tips-for-dnn/"/>
      <url>/2020/03/29/tips-for-dnn/</url>
      
        <content type="html"><![CDATA[<p>构建深度学习的三个步骤：<br><strong>①定义一系列函数$(define \ a \ set \ of \ function)$</strong><br><strong>②函数的拟合程度$(goodness \ of \ function)$</strong><br><strong>③选出最优的模型$(pick \ the \ best \ function)$</strong></p><p>当深度学习的深度很深，但是在$test$上表现并不好的时候，并不能马上断定就是$overfitting$，需要去看一下该模型在$train$上是否表现良好，如果再$train$上也没有表现的很好的话也不能马上认定就是$underfitting$，因为该模型的深度很深的话，说明该模型是有能力将数据拟合的，只是训练的方式不对。</p><p><strong><em>当模型在train上表现不好时可以考虑以下两点：</em></strong><br><strong>①换一个$activation function$</strong><br><strong>②改变$learning \  rate$</strong></p><p>首先对于第一个点，如果使用的$activation \  function$是$sigmoid$函数，因为$sigmoid$函数会将神经网络的输出压缩到$0$到$1$之间，当神经网络的层数过多的时候，越前面的神经网络的输出将会被压缩的越来越小直至消失，这就会造成梯度消失。导致的结果就是越前面的神经网络层的参数对最后输出的结果的影响越小，甚至是无影响，而越靠后的神经网络参数对输出的影响越大，这就容易造成模型表现不好。<br>所以我们一般会使用$ReLU$函数来代替$sigmoid$函数。<br>$ReLU$函数不仅<strong>计算速度更快，而且能解决梯度消失的问题</strong>。<br>而$Maxout$函数是在$ReLU$函数的基础上，取最大值，做法是类似于卷积神经网络中的池化层的作用。并且$ReLU$函数其实是$Maxout$函数的一种特殊的形式。</p><p>而对于第二个点，就是对$leraning \  rate$的调整。从最普通的$Gradient \  Descent$，就是用最$naive$的$learning \  rate$。而$Adagrad$就是在$learning \  rate$的基础上，除以此前每一次的梯度的平方和相加开根号。式子为$W^{t + 1}\leftarrow W^{t} - \frac{n}{\sqrt{\sum_{i=0}^{t}(g^{i})^{2}}}g^{t}$。<br>而$RMSProp$也是利用的计算此前梯度的方法，不同于$Adagrad$的是，$RMSProp$是通过每一次的迭代：<br>$W^{1}\leftarrow W^{0} - \frac{n}{\sigma ^{0}}g^{0}\quad \sigma^{0} =g^0$<br>$W^{2}\leftarrow W^{1} - \frac{n}{\sigma ^{1}}g^{1}\quad \sigma^{1} =\sqrt{\alpha (\sigma^{0})^{2}+(1-\alpha )(g^{1})^{2}}$<br>$\cdot \cdot \cdot$<br>$W^{t + 1}\leftarrow W^{t} - \frac{n}{\sigma ^{t}}g^{t}\quad \sigma^{t} =\sqrt{\alpha (\sigma^{t - 1})^{2}+(1-\alpha )(g^{t})^{2}}$<br>这样，通过$\alpha$就可以控制前面梯度和后面梯度占影响的比重。<br>还有一种基于动量想法的梯度下降优化方法，$Momentum$。<br>其想法是：设置一个初始的动量$v_0$，每一次计算梯度的时候，都需要加上上一个时刻的动量带来的影响。这种做法就不容易在做梯度下降的时候卡在局部最优解。<br>最后一种优化的方法就是$Adam$,它是前面两种方法$RMSProp$和$Momentum$的结合，是一种很快并且高效的方法。  </p><p><strong><em>当在$test$上表现不好的时候：</em></strong></p><p>我们也有一些解决可以尝试的办法：<br>①$Early \ Stopping$<br>②$Regularization(正则化)$<br>③$Dropout$  </p><p>当在训练的时候，很可能会遇到一种情况：训练的$loss$已经下降到一个值后又开始往上增加，这个时候我们就要用到$Early \ Stopping$，顾名思义，就是早一些停止训练，让我们用$loss$保持在最低值的模型去在$test$上验证。  </p><p>正则化分为$L_1$和$L_2$正则化，正则化就是在$loss$函数的后面加上一个偏置项。$L_1$正则化后面加的是$\left | \theta  \right |_1=\left | w_1 \right |+\left | w_2 \right |+\cdot \cdot \cdot$, $L_2$正则化后面加的是$\left | \theta  \right |_2={\left | w_1 \right |}^{2}+{\left | w_2 \right |}^{2}+\cdot \cdot \cdot$  </p><p>第三个方法就是$Dropout$，通过一定概率将某些$nuron$删除而得到新的一个较小的神经网络，进行训练，这样就相当于将一共有$2^n$种的小的神经网络进行训练后取结果的平均值。</p><p>模块化：<br>$deep \ learning$的好处就是模组化，尤其是在语音识别中的应用。模组化的意思是：将每一层的$neuron$看做一个模组，前面的模组是可以影响后面模组的判断的。例如做一个分类的问题的时候，假设分别红黄蓝三种颜色的物块，第一层的$basic \ calssifiers$已经做完。现在我们的数据里面红和黄的数据有很多，但是蓝的数据很少。这时候第二层可以通过第一层的$classifiers$来进行构建第二层的$calssifiers$，这样，利用上一层的分类来构建下一层的分类，即使蓝的数据很少，也可以做到不错的准确率。但是模组化并不需要我们人去做，机器学习是会自己去学习的$(The \ modularization\ is\ automatically\ learned\ from\ data)$。所以说$deep \ learning$所需要的数据其实是比较少的。</p><p> $deep \ learning$并不是说需要很多$data$，正是因为我们所有的$data$很少，所以我们才需要机器学会去做举一反三的事情，所以才是$deep \ learning$。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Training DNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch入门</title>
      <link href="/2020/03/28/pytorch/"/>
      <url>/2020/03/28/pytorch/</url>
      
        <content type="html"><![CDATA[<p><strong><em>一.$tensor$的创建:$torch.tensor()$</em></strong></p><pre class="line-numbers language-python"><code class="language-python">x_numpy <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x_torch <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x_numpy, x_torch'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x_numpy<span class="token punctuation">,</span> x_torch<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code> 输出结果为：</code></pre><pre><code>x_numpy, x_torch[0.1 0.2 0.3] tensor([0.1000, 0.2000, 0.3000])</code></pre><p><strong><em>二.$tensor$和$numpy$矩阵的转换：</em></strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'to and from numpy and pytorch'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_numpy<span class="token punctuation">)</span><span class="token punctuation">,</span> x_torch<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​    输出的结果为：</p><pre><code>to and from numpy and pytorchtensor([0.1000, 0.2000, 0.3000], dtype=torch.float64) [0.1 0.2 0.3]</code></pre><p>需要注意的是： $from\underline{} numpy()$是$torch$的内置函数，输入的是一个$numpy$的对象，输出将其转化为$tensor$类型输出。而$numpy()$是$torch$对象的一个方法，将$tensor$类型的对象转换为$numpy$输出。</p><p><strong><em>三.$tensor$和$numpy$矩阵是支持$+，-，*, /$运算的：</em></strong></p><pre class="line-numbers language-python"><code class="language-python">y_numpy <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_torch <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x+y"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x_numpy <span class="token operator">+</span> y_numpy<span class="token punctuation">,</span> x_torch <span class="token operator">+</span> y_torch<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​    输出结果为：</p><pre><code>x+y[3.1 4.2 5.3] tensor([3.1000, 4.2000, 5.3000])</code></pre><p><strong><em>四.许多在$numpy$中的函数，$pytorch$也有：</em></strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"norm"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x_numpy<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x_torch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong><em>五.如果我们只操作一个维度的向量，在$pytorch$中不用$axis$，而是使用$dim$：</em></strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"mean along the 0th dimension"</span><span class="token punctuation">)</span>x_numpy <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x_torch <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x_numpy<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x_torch<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>​    输出结果为：</p><pre><code>mean along the 0th dimension[2. 3.] tensor([2., 3.])</code></pre><hr><p><strong><em>六.$tensor.view()$可以$reshape tensor$的向量，和$numpy$中的$numpy.reshpe()$效果一样。同样的如果我们不知道一个向量的维度，可以将$-1$填入，他会自动判断向量的维度。</em></strong></p><pre class="line-numbers language-python"><code class="language-python">N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> W<span class="token punctuation">,</span> H <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> W<span class="token punctuation">,</span> H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> C<span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​    输出结果为：</p><pre><code>torch.Size([10000, 3, 28, 28])torch.Size([10000, 3, 784])torch.Size([10000, 3, 784])</code></pre><p><strong><em>七.存储计算图：</em></strong></p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># we set requires_grad=True to let PyTorch know to keep the graph</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>c <span class="token operator">=</span> a <span class="token operator">+</span> bd <span class="token operator">=</span> b <span class="token operator">+</span> <span class="token number">1</span>e <span class="token operator">=</span> c <span class="token operator">*</span> d<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'c'</span><span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'d'</span><span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'e'</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><img src="https://cdn.jsdelivr.net/gh/shw2018/cdn@1.0/sakura/img/loader/orange.progress-bar-stripe-loader.svg" data-original="https://colah.github.io/posts/2015-08-Backprop/img/tree-eval.png" alt="img" style="zoom:33%;"><p>​    输出结果为：</p><pre><code>c tensor(3., grad_fn=&lt;AddBackward0&gt;)d tensor(2., grad_fn=&lt;AddBackward0&gt;)e tensor(6., grad_fn=&lt;MulBackward0&gt;)</code></pre><p><strong><em>八.可以通过$backward()$函数一次将计算图中的梯度计算出:</em></strong></p><pre><code>def f(x):    return (x-2)**2def fp(x):    return 2*(x-2)x = torch.tensor([1.0], requires_grad=True)y = f(x)y.backward()print('Analytical f\'(x):', fp(x))print('PyTorch\'s f\'(x):', x.grad)</code></pre><p>可以看到输出的结果是一样的：</p><pre><code>Analytical f'(x): tensor([-2.], grad_fn=&lt;MulBackward0&gt;)PyTorch's f'(x): tensor([-2.])</code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">g</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">2</span><span class="token operator">*</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">grad_g</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token operator">*</span>w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token operator">*</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>z <span class="token operator">=</span> g<span class="token punctuation">(</span>w<span class="token punctuation">)</span>z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Analytical grad g(w)'</span><span class="token punctuation">,</span> grad_g<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'PyTorch\'s grad g(w)'</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出：</p><pre><code>Analytical grad g(w) tensor([2.0000, 5.2832])PyTorch's grad g(w) tensor([2.0000, 5.2832])</code></pre><p>有了梯度，我们就可以用来计算梯度下降：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>x<span class="token number">-2</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token keyword">def</span> <span class="token function">fp</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">2</span><span class="token operator">*</span><span class="token punctuation">(</span>x<span class="token number">-2</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>step_size <span class="token operator">=</span> <span class="token number">0.25</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'iter,\tx,\tf(x),\tf\'(x),\tf\'(x) pytorch'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    y <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># compute the gradient</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{},\t{:.3f},\t{:.3f},\t{:.3f},\t{:.3f}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">,</span> x<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    x<span class="token punctuation">.</span>data <span class="token operator">=</span> x<span class="token punctuation">.</span>data <span class="token operator">-</span> step_size <span class="token operator">*</span> x<span class="token punctuation">.</span>grad  <span class="token comment" spellcheck="true"># perform a GD update step</span>    <span class="token comment" spellcheck="true"># We need to zero the grad variable since the backward()</span>    <span class="token comment" spellcheck="true"># call accumulates the gradients in .grad instead of overwriting.</span>    <span class="token comment" spellcheck="true"># The detach_() is for efficiency. You do not need to worry too much about it.</span>    x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>detach_<span class="token punctuation">(</span><span class="token punctuation">)</span>    x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：</p><pre><code>iter,    x,    f(x),    f'(x),    f'(x) pytorch0,    5.000,    9.000,    6.000,    6.0001,    3.500,    2.250,    3.000,    3.0002,    2.750,    0.562,    1.500,    1.5003,    2.375,    0.141,    0.750,    0.7504,    2.188,    0.035,    0.375,    0.3755,    2.094,    0.009,    0.188,    0.1886,    2.047,    0.002,    0.094,    0.0947,    2.023,    0.001,    0.047,    0.0478,    2.012,    0.000,    0.023,    0.0239,    2.006,    0.000,    0.012,    0.01210,    2.003,    0.000,    0.006,    0.00611,    2.001,    0.000,    0.003,    0.00312,    2.001,    0.000,    0.001,    0.00113,    2.000,    0.000,    0.001,    0.00114,    2.000,    0.000,    0.000,    0.000</code></pre><p><strong><em>九.使用$pytorch$做$Linear Regression$：</em></strong></p><p>定义一个简单的线性模型：</p><pre class="line-numbers language-python"><code class="language-python">d <span class="token operator">=</span> <span class="token number">2</span>n <span class="token operator">=</span> <span class="token number">50</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n<span class="token punctuation">,</span>d<span class="token punctuation">)</span>true_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> X @ true_w <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.1</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'X shape'</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y shape'</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w shape'</span><span class="token punctuation">,</span> true_w<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>定义一个无bias的模型。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># define a linear model with no bias</span><span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> X @ w<span class="token comment" spellcheck="true"># the residual sum of squares loss function</span><span class="token keyword">def</span> <span class="token function">rss</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>y <span class="token operator">-</span> y_hat<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">/</span> n<span class="token comment" spellcheck="true"># analytical expression for the gradient</span><span class="token keyword">def</span> <span class="token function">grad_rss</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span>X<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> @ <span class="token punctuation">(</span>y <span class="token operator">-</span> X @ w<span class="token punctuation">)</span> <span class="token operator">/</span> nw <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span>loss <span class="token operator">=</span> rss<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Analytical gradient'</span><span class="token punctuation">,</span> grad_rss<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'PyTorch\'s gradient'</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>进行梯度下降：</p><pre class="line-numbers language-python"><code class="language-python">step_size <span class="token operator">=</span> <span class="token number">0.1</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'iter,\tloss,\tw'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span>    loss <span class="token operator">=</span> rss<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># compute the gradient of the loss</span>    w<span class="token punctuation">.</span>data <span class="token operator">=</span> w<span class="token punctuation">.</span>data <span class="token operator">-</span> step_size <span class="token operator">*</span> w<span class="token punctuation">.</span>grad <span class="token comment" spellcheck="true"># do a gradient descent step</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{},\t{:.2f},\t{}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>i<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># We need to zero the grad variable since the backward()</span>    <span class="token comment" spellcheck="true"># call accumulates the gradients in .grad instead of overwriting.</span>    <span class="token comment" spellcheck="true"># The detach_() is for efficiency. You do not need to worry too much about it.</span>    w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>    w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\ntrue w\t\t'</span><span class="token punctuation">,</span> true_w<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'estimated w\t'</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果：</p><pre><code>X shape torch.Size([50, 2])y shape torch.Size([50, 1])w shape torch.Size([2, 1])Analytical gradient [ 2.606523 -3.605597]PyTorch's gradient [ 2.606523  -3.6055958]iter,    loss,    w0,    6.28,    [0.4786954  0.72111917]1,    2.96,    [0.27993613 0.9474361 ]2,    2.13,    [0.10609908 1.1325792 ]3,    1.53,    [-0.04559225  1.2843454 ]4,    1.11,    [-0.1776925  1.409002 ]5,    0.80,    [-0.2925274  1.511596 ]6,    0.58,    [-0.3921964  1.5961986]7,    0.43,    [-0.47858146  1.6661003 ]8,    0.31,    [-0.5533598  1.7239654]9,    0.23,    [-0.6180189  1.7719555]10,    0.17,    [-0.6738725  1.8118278]11,    0.13,    [-0.72207654  1.8450135 ]12,    0.09,    [-0.7636454  1.8726808]13,    0.07,    [-0.79946655  1.8957849 ]14,    0.05,    [-0.8303146  1.9151086]15,    0.04,    [-0.85686433  1.9312946 ]16,    0.03,    [-0.87970257  1.9448717 ]17,    0.03,    [-0.8993387  1.9562759]18,    0.02,    [-0.91621447  1.9658674 ]19,    0.02,    [-0.9307121  1.9739441]true w         [-1.  2.]estimated w     [-0.9307121  1.9739441]</code></pre><p><strong><em>十.接下来使用$torch$的$Module$模块来构建模型：</em></strong></p><p>我们只需要给模型输入和输出的向量维度就可以。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nnd_in <span class="token operator">=</span> <span class="token number">3</span>d_hidden <span class="token operator">=</span> <span class="token number">4</span>d_out <span class="token operator">=</span> <span class="token number">1</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>                            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_in<span class="token punctuation">,</span> d_hidden<span class="token punctuation">)</span><span class="token punctuation">,</span>                            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_hidden<span class="token punctuation">,</span> d_out<span class="token punctuation">)</span><span class="token punctuation">,</span>                            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>                           <span class="token punctuation">)</span>example_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>transformed <span class="token operator">=</span> model<span class="token punctuation">(</span>example_tensor<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'transformed'</span><span class="token punctuation">,</span> transformed<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以知道我们的模型是输出是$transformed torch.Size([2, 1])$的。</p><p>我们可以访问模型的任意参数，使用$model$模块的$parameters()$函数：</p><pre class="line-numbers language-python"><code class="language-python">params <span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> params<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>输出为：</p><pre><code>Parameter containing:tensor([[-0.1239,  0.3218,  0.0660],        [ 0.4255, -0.0327,  0.1256],        [ 0.0171, -0.0812,  0.0283],        [ 0.2355, -0.5556, -0.5647]], requires_grad=True)Parameter containing:tensor([ 0.2152, -0.2082, -0.0993, -0.3068], requires_grad=True)Parameter containing:tensor([[ 0.3291, -0.0819,  0.0228,  0.0642]], requires_grad=True)Parameter containing:tensor([-0.3666], requires_grad=True)</code></pre><p>接下来需要定义损失函数，可以用$CrossEntropyLoss$或者$MSELoss$：</p><pre class="line-numbers language-python"><code class="language-python">mse_loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>input <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>target <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>loss <span class="token operator">=</span> mse_loss_fn<span class="token punctuation">(</span>input<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>$pytorch$定义了参数优化器，例如梯度下降等都在$torch.optim$中。</p><p>但是它不会为你计算梯度，所以你需要自己调用函数$backward()$，当你调用$backward()$前，你还需要调用$optim.zero\underline{} grad()$,因为$pytorch$的梯度是会相加的而不是覆盖原来的值。</p><p>另外类似$torch.optim.SGD()$的后面需要两个参数，一个是模型的参数$model.parameters()$,另一个是学习率$lr$。</p><p>一个简单的模型：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># create a simple model</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># create a simple dataset</span>X_simple <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_simple <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># create our optimizer</span>optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>mse_loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>y_hat <span class="token operator">=</span> model<span class="token punctuation">(</span>X_simple<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'model params before:'</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>loss <span class="token operator">=</span> mse_loss_fn<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y_simple<span class="token punctuation">)</span>optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'model params after:'</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong><em>十一.构建卷积神经网络:</em></strong></p><p> $pytorch$中有$torch.nn.Conv2d$函数实现卷积。他所需要的参数有四个$(N,C_{in},H_{in},W_{in})$。其中$N$是$batch size$, $C_{in}$是图片的通道数目，$H_{in}$和$W_{in}$分别是图片的高和宽。</p><p><strong><em>十二.数据：</em></strong></p><p>$torch.utils.data.Dataset$需要覆盖$\underline{}\underline{}len\underline{}\underline{}$和$\underline{}\underline{}getitem\underline{}\underline{}$方法，前者返回数据集的$size$,后者使数据集支持数组的下标寻址方式。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FaceLandmarksDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Face Landmarks dataset."""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> csv_file<span class="token punctuation">,</span> root_dir<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Args:            csv_file (string): Path to the csv file with annotations.            root_dir (string): Directory with all the images.            transform (callable, optional): Optional transform to be applied                on a sample.        """</span>        self<span class="token punctuation">.</span>landmarks_frame <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>csv_file<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>root_dir <span class="token operator">=</span> root_dir        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>landmarks_frame<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>is_tensor<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">:</span>            idx <span class="token operator">=</span> idx<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>        img_name <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>                                self<span class="token punctuation">.</span>landmarks_frame<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        image <span class="token operator">=</span> io<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>img_name<span class="token punctuation">)</span>        landmarks <span class="token operator">=</span> self<span class="token punctuation">.</span>landmarks_frame<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>        landmarks <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>landmarks<span class="token punctuation">]</span><span class="token punctuation">)</span>        landmarks <span class="token operator">=</span> landmarks<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        sample <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'image'</span><span class="token punctuation">:</span> image<span class="token punctuation">,</span> <span class="token string">'landmarks'</span><span class="token punctuation">:</span> landmarks<span class="token punctuation">}</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">:</span>            sample <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>sample<span class="token punctuation">)</span>        <span class="token keyword">return</span> sample<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python文件输入输出</title>
      <link href="/2020/03/28/python-wen-jian-shu-ru-shu-chu/"/>
      <url>/2020/03/28/python-wen-jian-shu-ru-shu-chu/</url>
      
        <content type="html"><![CDATA[<p>python读取文件使用open函数，返回一个文本对象，我们一般只会用到open函数的前面两个参数，第一个参数是要读取文件的名称，第二个参数是读取文件的模式。  </p><table><thead><tr><th>打开模式</th><th>执行操作</th></tr></thead><tbody><tr><td>‘r’</td><td>以只读方式打开文件（默认）</td></tr><tr><td>‘w’</td><td>以写入方式打开文件，会将文件覆盖</td></tr><tr><td>‘x’</td><td>如果文件已经存在，使用此模式会发生异常</td></tr><tr><td>‘a’</td><td>以写入方式打开，但不覆盖，会接着使用文件</td></tr><tr><td>‘b’</td><td>以二进制模式打开文件</td></tr><tr><td>‘t’</td><td>以文本模式打开（默认）</td></tr><tr><td>‘+’</td><td>可读可写模式</td></tr></tbody></table><p>读取文件的流程</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">try</span><span class="token punctuation">:</span>f <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'路径'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">finally</span><span class="token punctuation">:</span><span class="token keyword">if</span> f<span class="token punctuation">:</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是每次这么写都会比较麻烦。所以python引入了with语句来自动帮助我们调用close(方法)：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'路径'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>python文件对象提供了三个读取文件的方式，read(),realine(),readlines()。read() 每次读取整个文件，它通常用于将文件内容放到一个字符串变量中。如果文件大于可用内存，为了保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。<br>readlines() 之间的差异是后者一次读取整个文件，象 .read() 一样。.readlines() 自动将文件内容分析成一个行的列表，该列表可以由 Python 的 for … in … 结构进行处理。<br>readline() 每次只读取一行，通常比readlines() 慢得多。仅当没有足够内存可以一次读取整个文件时，才应该使用 readline()。<br>注意：这三种方法是把每行末尾的’\n’也读进来了，它并不会默认的把’\n’去掉，需要手动去掉。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>list <span class="token operator">=</span> f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>list输出<span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token string">'1\n'</span><span class="token punctuation">,</span> <span class="token string">'2\n'</span><span class="token punctuation">,</span> <span class="token string">'3\n'</span><span class="token punctuation">,</span> <span class="token string">'4\n'</span><span class="token punctuation">,</span><span class="token string">'5\n'</span><span class="token string">'6\n'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>list <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>list1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    list<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> list1<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>list输出<span class="token punctuation">[</span><span class="token string">'1'</span><span class="token punctuation">,</span> <span class="token string">'2'</span><span class="token punctuation">,</span> <span class="token string">'3'</span><span class="token punctuation">,</span> <span class="token string">'4'</span><span class="token punctuation">,</span> <span class="token string">'5'</span><span class="token punctuation">,</span> <span class="token string">'6'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>字符编码</strong></p><p>要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件：</p><pre class="line-numbers language-python"><code class="language-python">f <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'gbk'</span><span class="token punctuation">)</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python文件处理 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
